{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6afded4",
   "metadata": {},
   "source": [
    "문서 군집화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8754719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', 700)\n",
    "\n",
    "path = ''   # 파일 경로(다운 받아야 함)\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))\n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "for file_ in all_files:\n",
    "    df = pd.read_table(file_, index_col=None, header=0, encoding='latin1')\n",
    "\n",
    "    filename_ = file_.split('\\\\')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "\n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef238e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "lemmar = WordNetLemmatizer()\n",
    "\n",
    "# 입력으로 들어온 token 단어들에 대해서 lemmatization 어근 변환\n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "# TfidfVectorizer 객체 생성 시 tokenizer 인자로 해당 함수를 설정하여 lemmatization 적용\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8842d89f",
   "metadata": {},
   "source": [
    "TF-IDF 기반 Vectorization 적용 및 KMeans 군집화 수행\n",
    "\n",
    "1. Stemming/Lemmatization 같은 어근 변환은 TfidfVectorizer에서 지원하진 않으나 tokenizer 파라미터에 커스텀 어근 변환 함수를 적용하여 어근 변환 수행 가능\n",
    "2. TfidfVectorizer 생성자의 tokenizer 인자로 위에서 생성한 LemNormalize 함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da39ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english', ngram_range=(1, 2), min_df=0.05, max_df=0.85)\n",
    "\n",
    "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c9d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 5개의 집합으로 군집화\n",
    "km_cluster = KMeans(n_clusters=5, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01800d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label'] == 0].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53259517",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label'] == 1].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label'] == 2].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00969bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label'] == 3].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_df[document_df['cluster_label'] == 4].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091dc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 집합으로 군집화\n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "\n",
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.sort_values(by='cluster_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c44874",
   "metadata": {},
   "source": [
    "군집별 핵심 단어 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125df6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = km_cluster.cluster_centers_\n",
    "print('cluster_centers shape :', cluster_centers.shape)\n",
    "print(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e39a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_details(cluster_model, cluster_data, feature_names, clusters_num, top_n_features=10):\n",
    "    cluster_details = {}\n",
    "\n",
    "    centroid_feature_ordered_ind = cluster_model.cluster_centers_.argsort()[:,::-1]\n",
    "\n",
    "    for cluster_num in range(clusters_num):\n",
    "        cluster_details[cluster_num] = {}\n",
    "        cluster_details[cluster_num]['cluster'] = cluster_num\n",
    "\n",
    "        top_feature_indexes = centroid_feature_ordered_ind[cluster_num, :top_n_features]\n",
    "        top_features = [feature_names[ind] for ind in top_feature_indexes]\n",
    "\n",
    "        top_feature_values = cluster_model.cluster_centers_[cluster_num, top_feature_indexes].tolist()\n",
    "\n",
    "        cluster_details[cluster_num]['top_features'] = top_features\n",
    "        cluster_details[cluster_num]['top_features_value'] = top_feature_values\n",
    "        filenames = cluster_data[cluster_data['cluster_label'] == cluster_num]['filename']\n",
    "        filenames = filenames.values.tolist()\n",
    "        cluster_details[cluster_num]['filenames'] = filenames\n",
    "\n",
    "    return cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4749e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_details(cluster_details):\n",
    "    for cluster_num, cluster_detail in cluster_details.items():\n",
    "        print('####### Cluster {0}'.format(cluster_num))\n",
    "        print('Top features:', cluster_detail['top_features'])\n",
    "        print('Reviews 파일명 :',cluster_detail['filenames'][:7])\n",
    "        print('==================================================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59da353",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vect.get_feature_names()\n",
    "\n",
    "cluster_details = get_cluster_details(cluster_model=km_cluster, cluster_data=document_df,\\\n",
    "                                  feature_names=feature_names, clusters_num=3, top_n_features=10 )\n",
    "print_cluster_details(cluster_details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
