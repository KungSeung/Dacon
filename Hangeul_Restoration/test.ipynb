{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "148ea1e3",
   "metadata": {},
   "source": [
    "난독화된 한글 리뷰 복원 및 생성 AI 경진대회 </br>\n",
    "+ 플러스 알파 : (나쁨)0~5(좋음)점에서 몇 점에 해당하는지 판단할 수 있다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb95d8d",
   "metadata": {},
   "source": [
    "Basline Code\n",
    "\n",
    "단어 사전 기반 복원과 LLM(Gemma-7b)을 활용한 텍스트 변환 및 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298f8e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./data/train.csv', encoding='utf-8-sig')\n",
    "test = pd.read_csv('./data/test.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b265e6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>별 한 게토 았깝땀. 왜 싸람듯릭 펼 1캐를 쥰눈징 컥꺾폰 싸람믐롯섞 맒록 섧멍핥쟈...</td>\n",
       "      <td>별 한 개도 아깝다. 왜 사람들이 별 1개를 주는지 겪어본 사람으로서 말로 설명하자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>잚많 쟉꼬 갉 태 좋눼욥. 차못동 줆 ㅋ</td>\n",
       "      <td>잠만 자고 갈 때 좋네요. 잠옷도 줌 ㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>절테 간면 않 된는 굣 멥몫</td>\n",
       "      <td>절대 가면 안 되는 곳 메모</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>야... 칵컥 좋꾜 부됴 뼝 뚫렷썹 신원햐쥠만 닮패 넴센 밌쪄벅림. 샥퀘 핥류만 묵...</td>\n",
       "      <td>아... 가격 좋고 뷰도 뻥 뚫려서 시원하지만 담배 냄새 미쳐버림. 싸게 하루만 묵...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>집윈 축쳐눌료 딴너왓눈뎁 카셩뷔 좋곱 칼쿰한네올. 쩌럼한뒈 뮬콰 욺료토 잊쿄 빻토 ...</td>\n",
       "      <td>지인 추천으로 다녀왔는데 가성비 좋고 깔끔하네요. 저렴한데 물과 음료도 있고 방도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN_00005</td>\n",
       "      <td>펀냔휜 잘 쉭곶 왔쑵닝따. 준윙에 맏쥡됴 만학썩 좋흖 겼 갇따용.</td>\n",
       "      <td>편안히 잘 쉬고 왔습니다. 주위에 맛집도 많아서 좋은 것 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRAIN_00006</td>\n",
       "      <td>쓰윔튿룸위 깝써칙갖 있네 ㅋ 꼭굽 췸규웨 낑펙투, 합뻔퓨 옥쪽, 캬뻬 깥은 띰 떼잎...</td>\n",
       "      <td>스위트룸의 값어치가 있네 ㅋ 고급 침구에 킹베드, 하버뷰 욕조, 카페 같은 티 테이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRAIN_00007</td>\n",
       "      <td>쨉빵뮨 의싸 쩐허 없쓺. 씬랏슬톄잎뾰댜 떠 짝음. 홈뗄 줄찾짱 15땜만 캉눙. 혹텔...</td>\n",
       "      <td>재방문 의사 전혀 없음. 신라스테이보다 더 작음. 호텔 주차장 15대만 가능. 호텔...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TRAIN_00008</td>\n",
       "      <td>념묵 멎쥑교 꽁귀 좋습니닸. 췐곡윕뉘댜!</td>\n",
       "      <td>너무 멋지고 공기 좋습니다. 최고입니다!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRAIN_00009</td>\n",
       "      <td>짱졈: 쩡켤함, 츄챠 씨셜 죠흠, 쉼섦 좋음.   단젊: 줏짢 츌짜할 떼 뷸뻔함, ...</td>\n",
       "      <td>장점: 청결함, 주차 시설 좋음, 시설 좋음.   단점: 주차 출차할 때 불편함, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                              input  \\\n",
       "0  TRAIN_00000  별 한 게토 았깝땀. 왜 싸람듯릭 펼 1캐를 쥰눈징 컥꺾폰 싸람믐롯섞 맒록 섧멍핥쟈...   \n",
       "1  TRAIN_00001                             잚많 쟉꼬 갉 태 좋눼욥. 차못동 줆 ㅋ   \n",
       "2  TRAIN_00002                                    절테 간면 않 된는 굣 멥몫   \n",
       "3  TRAIN_00003  야... 칵컥 좋꾜 부됴 뼝 뚫렷썹 신원햐쥠만 닮패 넴센 밌쪄벅림. 샥퀘 핥류만 묵...   \n",
       "4  TRAIN_00004  집윈 축쳐눌료 딴너왓눈뎁 카셩뷔 좋곱 칼쿰한네올. 쩌럼한뒈 뮬콰 욺료토 잊쿄 빻토 ...   \n",
       "5  TRAIN_00005               펀냔휜 잘 쉭곶 왔쑵닝따. 준윙에 맏쥡됴 만학썩 좋흖 겼 갇따용.   \n",
       "6  TRAIN_00006  쓰윔튿룸위 깝써칙갖 있네 ㅋ 꼭굽 췸규웨 낑펙투, 합뻔퓨 옥쪽, 캬뻬 깥은 띰 떼잎...   \n",
       "7  TRAIN_00007  쨉빵뮨 의싸 쩐허 없쓺. 씬랏슬톄잎뾰댜 떠 짝음. 홈뗄 줄찾짱 15땜만 캉눙. 혹텔...   \n",
       "8  TRAIN_00008                             념묵 멎쥑교 꽁귀 좋습니닸. 췐곡윕뉘댜!   \n",
       "9  TRAIN_00009  짱졈: 쩡켤함, 츄챠 씨셜 죠흠, 쉼섦 좋음.   단젊: 줏짢 츌짜할 떼 뷸뻔함, ...   \n",
       "\n",
       "                                              output  \n",
       "0  별 한 개도 아깝다. 왜 사람들이 별 1개를 주는지 겪어본 사람으로서 말로 설명하자...  \n",
       "1                             잠만 자고 갈 때 좋네요. 잠옷도 줌 ㅋ  \n",
       "2                                    절대 가면 안 되는 곳 메모  \n",
       "3  아... 가격 좋고 뷰도 뻥 뚫려서 시원하지만 담배 냄새 미쳐버림. 싸게 하루만 묵...  \n",
       "4  지인 추천으로 다녀왔는데 가성비 좋고 깔끔하네요. 저렴한데 물과 음료도 있고 방도 ...  \n",
       "5               편안히 잘 쉬고 왔습니다. 주위에 맛집도 많아서 좋은 것 같아요.  \n",
       "6  스위트룸의 값어치가 있네 ㅋ 고급 침구에 킹베드, 하버뷰 욕조, 카페 같은 티 테이...  \n",
       "7  재방문 의사 전혀 없음. 신라스테이보다 더 작음. 호텔 주차장 15대만 가능. 호텔...  \n",
       "8                             너무 멋지고 공기 좋습니다. 최고입니다!  \n",
       "9  장점: 청결함, 주차 시설 좋음, 시설 좋음.   단점: 주차 출차할 때 불편함, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6043c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 생성\n",
    "\n",
    "match_dict = {}\n",
    "\n",
    "for input_text, output_text in zip(train['input'], train['output']):\n",
    "    input_words = input_text.split()\n",
    "    output_words = output_text.split()\n",
    "    for iw, ow in zip(input_words, output_words):\n",
    "        match_dict[iw] = ow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da42d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환 적용\n",
    "\n",
    "def replace_words(input_text, match_dict):\n",
    "    words = input_text.split()\n",
    "    replaced_words = [match_dict.get(word, word) for word in words]\n",
    "    return \" \".join(replaced_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24ce27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_reviews = test['input'].apply(lambda x:replace_words(x, match_dict)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee3af594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "submission = pd.read_csv('./data/sample_submission.csv', encoding='utf-8-sig')\n",
    "submission['output'] = converted_reviews\n",
    "submission.to_csv('./baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1acba18",
   "metadata": {},
   "source": [
    "LLM활용 (Gemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ec68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "\n",
    "train = pd.read_csv('./data/train.csv', encoding='utf-8-sig')\n",
    "test = pd.read_csv('./data/test.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Load\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type= 'nf4',\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model_id = 'beomi/gemma-ko-7b'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad3a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "pipe = pipeline(\n",
    "    task = \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "restored_reviews = []\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    query = row['input']\n",
    "\n",
    "    messages = [\n",
    "         {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a helpful assistant specializing in restoring obfuscated Korean reviews. \"\n",
    "                \"Your task is to transform the given obfuscated Korean review into a clear, correct, \"\n",
    "                \"and natural-sounding Korean review that reflects its original meaning. \"\n",
    "                \"Below are examples of obfuscated Korean reviews and their restored forms:\\n\\n\"\n",
    "                f\"Example, {samples}\"  \n",
    "                \"Spacing and word length in the output must be restored to the same as in the input. \"\n",
    "                \"Do not provide any description. Print only in Korean.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"input : {query}, output : \"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    prompt = \"\\n\".join([m[\"content\"] for m in messages]).strip()\n",
    "        \n",
    "\n",
    "    outputs = pipe(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        temperature=0.2,\n",
    "        top_p=0.9,\n",
    "        max_new_tokens=len(query),\n",
    "        eos_token_id=pipe.tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    generated_text = outputs[0]['generated_text']\n",
    "    result = generated_text[len(prompt):].strip()\n",
    "        \n",
    "\n",
    "    restored_reviews.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778686ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "submission = pd.read_csv('./sample_submission.csv', encoding='utf-8-sig')\n",
    "submission['output'] = restored_reviews\n",
    "submission.to_csv('./baseline_submission.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a338bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('./train.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a1568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>별 한 게토 았깝땀. 왜 싸람듯릭 펼 1캐를 쥰눈징 컥꺾폰 싸람믐롯섞 맒록 섧멍핥쟈...</td>\n",
       "      <td>별 한 개도 아깝다. 왜 사람들이 별 1개를 주는지 겪어본 사람으로서 말로 설명하자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>잚많 쟉꼬 갉 태 좋눼욥. 차못동 줆 ㅋ</td>\n",
       "      <td>잠만 자고 갈 때 좋네요. 잠옷도 줌 ㅋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>절테 간면 않 된는 굣 멥몫</td>\n",
       "      <td>절대 가면 안 되는 곳 메모</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>야... 칵컥 좋꾜 부됴 뼝 뚫렷썹 신원햐쥠만 닮패 넴센 밌쪄벅림. 샥퀘 핥류만 묵...</td>\n",
       "      <td>아... 가격 좋고 뷰도 뻥 뚫려서 시원하지만 담배 냄새 미쳐버림. 싸게 하루만 묵...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>집윈 축쳐눌료 딴너왓눈뎁 카셩뷔 좋곱 칼쿰한네올. 쩌럼한뒈 뮬콰 욺료토 잊쿄 빻토 ...</td>\n",
       "      <td>지인 추천으로 다녀왔는데 가성비 좋고 깔끔하네요. 저렴한데 물과 음료도 있고 방도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN_00005</td>\n",
       "      <td>펀냔휜 잘 쉭곶 왔쑵닝따. 준윙에 맏쥡됴 만학썩 좋흖 겼 갇따용.</td>\n",
       "      <td>편안히 잘 쉬고 왔습니다. 주위에 맛집도 많아서 좋은 것 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRAIN_00006</td>\n",
       "      <td>쓰윔튿룸위 깝써칙갖 있네 ㅋ 꼭굽 췸규웨 낑펙투, 합뻔퓨 옥쪽, 캬뻬 깥은 띰 떼잎...</td>\n",
       "      <td>스위트룸의 값어치가 있네 ㅋ 고급 침구에 킹베드, 하버뷰 욕조, 카페 같은 티 테이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TRAIN_00007</td>\n",
       "      <td>쨉빵뮨 의싸 쩐허 없쓺. 씬랏슬톄잎뾰댜 떠 짝음. 홈뗄 줄찾짱 15땜만 캉눙. 혹텔...</td>\n",
       "      <td>재방문 의사 전혀 없음. 신라스테이보다 더 작음. 호텔 주차장 15대만 가능. 호텔...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TRAIN_00008</td>\n",
       "      <td>념묵 멎쥑교 꽁귀 좋습니닸. 췐곡윕뉘댜!</td>\n",
       "      <td>너무 멋지고 공기 좋습니다. 최고입니다!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRAIN_00009</td>\n",
       "      <td>짱졈: 쩡켤함, 츄챠 씨셜 죠흠, 쉼섦 좋음.   단젊: 줏짢 츌짜할 떼 뷸뻔함, ...</td>\n",
       "      <td>장점: 청결함, 주차 시설 좋음, 시설 좋음.   단점: 주차 출차할 때 불편함, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRAIN_00010</td>\n",
       "      <td>편힘 30퓬 넒계 쉰효 밭았써 긷타린는 쭐 봤욺면써 먈 얀항교 윗딱갸 거우 좌훽전을...</td>\n",
       "      <td>뻔히 30분 넘게 신호 받아서 기다리는 줄 봤으면서 말 안하고 있다가 겨우 좌회전을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRAIN_00011</td>\n",
       "      <td>켱취 좋숲닐따! :)</td>\n",
       "      <td>경치 좋습니다! :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TRAIN_00012</td>\n",
       "      <td>죽펴닛 쪼옹헤셔 좋앝교 임 쩡또 샹탬먼 졍말 휼룽햇숲뉘댜. 댜움웨 풋싼눼 꺌 일뤼 ...</td>\n",
       "      <td>주변이 조용해서 좋았고 이 정도 상태면 정말 훌륭했습니다. 다음에 부산에 갈 일이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TRAIN_00013</td>\n",
       "      <td>2023. 1. 7. 냐체토 얘프꼬 읾몲 땍또 얘프꾜 읾츌 탱됴 얘뼈오. 웨뿌 욺싶...</td>\n",
       "      <td>2023. 1. 7. 낮에도 예쁘고 일몰 때도 예쁘고 일출 때도 예뻐요. 외부 음식...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TRAIN_00014</td>\n",
       "      <td>퓨까 념뮴 좋얏곬, 샀창닒됴 넒뮤 췬졀학세오.</td>\n",
       "      <td>뷰가 너무 좋았고, 사장님도 너무 친절하세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRAIN_00015</td>\n",
       "      <td>쫄용햐닌 좋숩뉘탸. 쩌움 옮면 죡큼 닿황할 숯토 윗엊요. 쭙변예 얌뭅걷돎 엾였석.</td>\n",
       "      <td>조용하니 좋습니다. 처음 오면 조금 당황할 수도 있어요. 주변에 아무것도 없어서.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TRAIN_00016</td>\n",
       "      <td>쯩깐 쏘움뮐 씸함. 윗충 쿵꿍 쉼함. 엽칩 문 닫눈 쏘립 끙계 뜰륌.</td>\n",
       "      <td>층간 소음이 심함. 윗층 쿵쿵 심함. 옆집 문 닫는 소리 크게 들림.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRAIN_00017</td>\n",
       "      <td>찐차 섕갸캣떤 겆볶타 녀뮴 좋햐욘!! 욧선뿌돐 념뮴 좋핫써 요쟘맙쟎 쏠리 칡럿엇욧 ...</td>\n",
       "      <td>진짜 생각했던 것보다 너무 좋아요!! 오션뷰도 너무 좋아서 오자마자 소리 질렀어요 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TRAIN_00018</td>\n",
       "      <td>왕... 꺅깔요맵 훈깆룰 면져 봐서아 함는뒈... 융션 찔뤼샨 등싼 훌 퓻샨 쥐윈괌...</td>\n",
       "      <td>와... 카카오맵 후기를 먼저 봤어야 하는데... 우선 지리산 등산 후 부산 지인과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TRAIN_00019</td>\n",
       "      <td>빳닻갉 압 덱갖쪼김 갉 숟 윗눈 풀 삘랴는 줴한쩍귀랴 10멍 까눙한 따위트얾외잉료 ...</td>\n",
       "      <td>바닷가 앞 대가족이 갈 수 있는 불 빌라는 제한적이라 10명 가능한 타이드어웨이로 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                              input  \\\n",
       "0   TRAIN_00000  별 한 게토 았깝땀. 왜 싸람듯릭 펼 1캐를 쥰눈징 컥꺾폰 싸람믐롯섞 맒록 섧멍핥쟈...   \n",
       "1   TRAIN_00001                             잚많 쟉꼬 갉 태 좋눼욥. 차못동 줆 ㅋ   \n",
       "2   TRAIN_00002                                    절테 간면 않 된는 굣 멥몫   \n",
       "3   TRAIN_00003  야... 칵컥 좋꾜 부됴 뼝 뚫렷썹 신원햐쥠만 닮패 넴센 밌쪄벅림. 샥퀘 핥류만 묵...   \n",
       "4   TRAIN_00004  집윈 축쳐눌료 딴너왓눈뎁 카셩뷔 좋곱 칼쿰한네올. 쩌럼한뒈 뮬콰 욺료토 잊쿄 빻토 ...   \n",
       "5   TRAIN_00005               펀냔휜 잘 쉭곶 왔쑵닝따. 준윙에 맏쥡됴 만학썩 좋흖 겼 갇따용.   \n",
       "6   TRAIN_00006  쓰윔튿룸위 깝써칙갖 있네 ㅋ 꼭굽 췸규웨 낑펙투, 합뻔퓨 옥쪽, 캬뻬 깥은 띰 떼잎...   \n",
       "7   TRAIN_00007  쨉빵뮨 의싸 쩐허 없쓺. 씬랏슬톄잎뾰댜 떠 짝음. 홈뗄 줄찾짱 15땜만 캉눙. 혹텔...   \n",
       "8   TRAIN_00008                             념묵 멎쥑교 꽁귀 좋습니닸. 췐곡윕뉘댜!   \n",
       "9   TRAIN_00009  짱졈: 쩡켤함, 츄챠 씨셜 죠흠, 쉼섦 좋음.   단젊: 줏짢 츌짜할 떼 뷸뻔함, ...   \n",
       "10  TRAIN_00010  편힘 30퓬 넒계 쉰효 밭았써 긷타린는 쭐 봤욺면써 먈 얀항교 윗딱갸 거우 좌훽전을...   \n",
       "11  TRAIN_00011                                        켱취 좋숲닐따! :)   \n",
       "12  TRAIN_00012  죽펴닛 쪼옹헤셔 좋앝교 임 쩡또 샹탬먼 졍말 휼룽햇숲뉘댜. 댜움웨 풋싼눼 꺌 일뤼 ...   \n",
       "13  TRAIN_00013  2023. 1. 7. 냐체토 얘프꼬 읾몲 땍또 얘프꾜 읾츌 탱됴 얘뼈오. 웨뿌 욺싶...   \n",
       "14  TRAIN_00014                          퓨까 념뮴 좋얏곬, 샀창닒됴 넒뮤 췬졀학세오.   \n",
       "15  TRAIN_00015      쫄용햐닌 좋숩뉘탸. 쩌움 옮면 죡큼 닿황할 숯토 윗엊요. 쭙변예 얌뭅걷돎 엾였석.   \n",
       "16  TRAIN_00016             쯩깐 쏘움뮐 씸함. 윗충 쿵꿍 쉼함. 엽칩 문 닫눈 쏘립 끙계 뜰륌.   \n",
       "17  TRAIN_00017  찐차 섕갸캣떤 겆볶타 녀뮴 좋햐욘!! 욧선뿌돐 념뮴 좋핫써 요쟘맙쟎 쏠리 칡럿엇욧 ...   \n",
       "18  TRAIN_00018  왕... 꺅깔요맵 훈깆룰 면져 봐서아 함는뒈... 융션 찔뤼샨 등싼 훌 퓻샨 쥐윈괌...   \n",
       "19  TRAIN_00019  빳닻갉 압 덱갖쪼김 갉 숟 윗눈 풀 삘랴는 줴한쩍귀랴 10멍 까눙한 따위트얾외잉료 ...   \n",
       "\n",
       "                                               output  \n",
       "0   별 한 개도 아깝다. 왜 사람들이 별 1개를 주는지 겪어본 사람으로서 말로 설명하자...  \n",
       "1                              잠만 자고 갈 때 좋네요. 잠옷도 줌 ㅋ  \n",
       "2                                     절대 가면 안 되는 곳 메모  \n",
       "3   아... 가격 좋고 뷰도 뻥 뚫려서 시원하지만 담배 냄새 미쳐버림. 싸게 하루만 묵...  \n",
       "4   지인 추천으로 다녀왔는데 가성비 좋고 깔끔하네요. 저렴한데 물과 음료도 있고 방도 ...  \n",
       "5                편안히 잘 쉬고 왔습니다. 주위에 맛집도 많아서 좋은 것 같아요.  \n",
       "6   스위트룸의 값어치가 있네 ㅋ 고급 침구에 킹베드, 하버뷰 욕조, 카페 같은 티 테이...  \n",
       "7   재방문 의사 전혀 없음. 신라스테이보다 더 작음. 호텔 주차장 15대만 가능. 호텔...  \n",
       "8                              너무 멋지고 공기 좋습니다. 최고입니다!  \n",
       "9   장점: 청결함, 주차 시설 좋음, 시설 좋음.   단점: 주차 출차할 때 불편함, ...  \n",
       "10  뻔히 30분 넘게 신호 받아서 기다리는 줄 봤으면서 말 안하고 있다가 겨우 좌회전을...  \n",
       "11                                        경치 좋습니다! :)  \n",
       "12  주변이 조용해서 좋았고 이 정도 상태면 정말 훌륭했습니다. 다음에 부산에 갈 일이 ...  \n",
       "13  2023. 1. 7. 낮에도 예쁘고 일몰 때도 예쁘고 일출 때도 예뻐요. 외부 음식...  \n",
       "14                          뷰가 너무 좋았고, 사장님도 너무 친절하세요.  \n",
       "15      조용하니 좋습니다. 처음 오면 조금 당황할 수도 있어요. 주변에 아무것도 없어서.  \n",
       "16             층간 소음이 심함. 윗층 쿵쿵 심함. 옆집 문 닫는 소리 크게 들림.  \n",
       "17  진짜 생각했던 것보다 너무 좋아요!! 오션뷰도 너무 좋아서 오자마자 소리 질렀어요 ...  \n",
       "18  와... 카카오맵 후기를 먼저 봤어야 하는데... 우선 지리산 등산 후 부산 지인과...  \n",
       "19  바닷가 앞 대가족이 갈 수 있는 불 빌라는 제한적이라 10명 가능한 타이드어웨이로 ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "HangeulFile = pd.read_csv('./data/train.csv')\n",
    "HangeulFile.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac0613",
   "metadata": {},
   "source": [
    "문장 길이 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944895a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 길이 체크\n",
      " isSameLen\n",
      "True     10935\n",
      "False      328\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def checkSentenceLen():\n",
    "    input_length = HangeulFile['input'].str.len()\n",
    "    output_length  = HangeulFile['output'].str.len()\n",
    "    HangeulFile['isSameLen'] = input_length == output_length\n",
    "    print('문장 길이 체크\\n', HangeulFile['isSameLen'].value_counts())\n",
    "\n",
    "checkSentenceLen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f73cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['쩡결학꼬 찐절하쉬넥오']\n",
      "['청결하고 친절하시네요 ']\n",
      "문장 길이 체크\n",
      " isSameLen\n",
      "True    11263\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "HangeulFile[HangeulFile['isSameLen'] == False]\n",
    "\n",
    "# input_length+1 => output_length\n",
    "# ex) ID = TRAIN_00069\n",
    "input_text = HangeulFile[HangeulFile['ID'] == 'TRAIN_00069']['input']\n",
    "output_text = HangeulFile[HangeulFile['ID'] == 'TRAIN_00069']['output']\n",
    "# output_text 뒤에 공백 존재\n",
    "print(list(input_text))\n",
    "print(list(output_text))\n",
    "\n",
    "# 공백 제거\n",
    "HangeulFile['output'] = HangeulFile['output'].str.rstrip()\n",
    "checkSentenceLen()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a214771",
   "metadata": {},
   "source": [
    "특징\n",
    "\n",
    "0. 문장 공백 유지 </br> \n",
    "1. 리뷰데이터이기 때문에 띄어쓰기는 따로 처리 x</br>\n",
    "2. ㄱ -> ㅋ, ㄱ -> ㄲ 로 쓰는 경우가 많음</br>\n",
    "    a. 된소리, 거센소리를 평음으로 바꾸는 작업이 필요</br>\n",
    "3. 받침을 의도적으로 넣는 경우가 많음 </br>\n",
    "    a. 받침을 의도적으로 넣은 경우 삭제가 필요함</br>\n",
    "    * 아직 원래 있었던 받침인지 아닌지를 모르니 일단 다 삭제해보자</br>\n",
    "    b. 대신 필요한 받침인지 아닌지 구분이 필요함</br>\n",
    "4. 받침을 대체하는 것도 많음. 응대 -> 읗뎃</br>\n",
    "    a. 대체된 받침인지도 구분할 줄 알아야 함</br>\n",
    "5. 대 -> 데 아이 어이도 바꿈</br>\n",
    "6. 종성이 랉, 홅, 섧 같은 자음의 조합으로도 나타남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9718e2",
   "metadata": {},
   "source": [
    "된소리되기 현상</br>\n",
    "깍두기 -> 깍뚜기</br>\n",
    "\n",
    "사이시옷 현상</br>\n",
    "심고있다 -> 심꼬있다</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30f270",
   "metadata": {},
   "source": [
    "형태소 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef98cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['별', ' ', '한', ' ', '게토', ' ', '았깝땀', '.', ' ', '왜', ' ', '싸람', '듯릭', ' ', '펼', ' ', '1', '캐', '를', ' ', '쥰눈징', ' ', '컥꺾폰', ' ', '싸람', '믐롯섞', ' ', '맒록', ' ', '섧멍핥쟈닐', ' ', '탯끎룐눈', ' ', '녀뮤', ' ', '퀼교', '...', ' ', '야뭍툰', ' ', '둠', ' ', '변', ' ', '닺씨', ' ', '깍', '낄', ' ', '싫훈', ' ', '굣', '.', ' ', '깸삥읊', ' ', '20', '여', ' ', '년', ' ', '댜녁뵨', ' ', '곧', ' ', '중', ' ', '쩨윌', ' ', '귑푼', ' ', '낙', '팠', '떤', ' ', '곶', '.']\n"
     ]
    }
   ],
   "source": [
    "# 한국어 형태소 분석 라이브러리\n",
    "# Okt : Open Korea text\n",
    "# Mecab, Komoran, Hannanum, Kkma\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "text = HangeulFile[HangeulFile['ID'] == 'TRAIN_00000']['input'].iloc[0]\n",
    "words = text.split()\n",
    "\n",
    "# 문장 공백 유지\n",
    "tokens = []\n",
    "for word in words:\n",
    "    tokens.extend(okt.morphs(word))\n",
    "    tokens.append(' ')\n",
    "\n",
    "if tokens and tokens[-1] == ' ':\n",
    "    tokens = tokens[:-1]\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39fd67d",
   "metadata": {},
   "source": [
    "거센소리, 된소리 -> 평음 맵핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91113816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예사소리(평음) : ㄱ, ㄷ, ㅂ, ㅅ, ㅈ\n",
    "# 된소리 : ㄲ, ㄸ, ㅃ, ㅆ, ㅉ\n",
    "# 거센소리 : ㅋ, ㅌ, ㅍ, ㅊ\n",
    "aspirated_consonants = {'ㅋ':'ㄱ', 'ㅌ':'ㄷ', 'ㅍ':'ㅂ', 'ㅊ':'ㅅ', 'ㅊ':'ㅈ'}\n",
    "strengthened_consonants = {'ㄲ':'ㄱ', 'ㄸ':'ㄷ', 'ㅃ':'ㅂ', 'ㅆ':'ㅅ', 'ㅉ':'ㅈ'}\n",
    "\n",
    "def to_plainWord(x):\n",
    "    # 초성 변환\n",
    "    if x in strengthened_consonants:\n",
    "        x = strengthened_consonants[x]\n",
    "    elif x in aspirated_consonants:\n",
    "        x = aspirated_consonants[x]\n",
    "\n",
    "    # 종성 변환 (예: ㅆ, ㅉ 등이 종성으로 올 경우)\n",
    "    if x in strengthened_consonants:\n",
    "        x = strengthened_consonants[x]\n",
    "    elif x in aspirated_consonants:\n",
    "        x = aspirated_consonants[x]\n",
    "\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafccb89",
   "metadata": {},
   "source": [
    "(일단) 받침 제거</br>\n",
    "빳닻갉 -> 바닷가 어떻게??</br>\n",
    "밧닷갉 -> 바다가 초성,중성 평음화 + 받침삭제하면 이렇게 되어버림</br>\n",
    "\n",
    "** 문맥 기반 언어 모델 활용</br>\n",
    "편지를 밝았다 x</br>\n",
    "편지를 받았다 o</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36252f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1bea2",
   "metadata": {},
   "source": [
    "tokens는 조합된 음절 </br>\n",
    "1. 자음, 모음 분리 </br>\n",
    "2. 된소리, 거센소리 -> 평음으로 치환 </br>\n",
    "3. 다시 조합</br>\n",
    "\n",
    "대표적인 라이브러리 : hgtk, jamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be1d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ㅂ', 'ㅕ', 'ㄹ')]\n",
      "[' ']\n",
      "[('ㅎ', 'ㅏ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㄱ', 'ㅔ', ''), ('ㅌ', 'ㅗ', '')]\n",
      "[' ']\n",
      "[('ㅇ', 'ㅏ', 'ㅆ'), ('ㄲ', 'ㅏ', 'ㅂ'), ('ㄸ', 'ㅏ', 'ㅁ')]\n",
      "['.']\n",
      "[' ']\n",
      "[('ㅇ', 'ㅙ', '')]\n",
      "[' ']\n",
      "[('ㅆ', 'ㅏ', ''), ('ㄹ', 'ㅏ', 'ㅁ')]\n",
      "[('ㄷ', 'ㅡ', 'ㅅ'), ('ㄹ', 'ㅣ', 'ㄱ')]\n",
      "[' ']\n",
      "[('ㅍ', 'ㅕ', 'ㄹ')]\n",
      "[' ']\n",
      "['1']\n",
      "[('ㅋ', 'ㅐ', '')]\n",
      "[('ㄹ', 'ㅡ', 'ㄹ')]\n",
      "[' ']\n",
      "[('ㅈ', 'ㅠ', 'ㄴ'), ('ㄴ', 'ㅜ', 'ㄴ'), ('ㅈ', 'ㅣ', 'ㅇ')]\n",
      "[' ']\n",
      "[('ㅋ', 'ㅓ', 'ㄱ'), ('ㄲ', 'ㅓ', 'ㄲ'), ('ㅍ', 'ㅗ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㅆ', 'ㅏ', ''), ('ㄹ', 'ㅏ', 'ㅁ')]\n",
      "[('ㅁ', 'ㅡ', 'ㅁ'), ('ㄹ', 'ㅗ', 'ㅅ'), ('ㅅ', 'ㅓ', 'ㄲ')]\n",
      "[' ']\n",
      "[('ㅁ', 'ㅏ', 'ㄻ'), ('ㄹ', 'ㅗ', 'ㄱ')]\n",
      "[' ']\n",
      "[('ㅅ', 'ㅓ', 'ㄼ'), ('ㅁ', 'ㅓ', 'ㅇ'), ('ㅎ', 'ㅏ', 'ㄾ'), ('ㅈ', 'ㅑ', ''), ('ㄴ', 'ㅣ', 'ㄹ')]\n",
      "[' ']\n",
      "[('ㅌ', 'ㅐ', 'ㅅ'), ('ㄲ', 'ㅡ', 'ㄻ'), ('ㄹ', 'ㅛ', 'ㄴ'), ('ㄴ', 'ㅜ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㄴ', 'ㅕ', ''), ('ㅁ', 'ㅠ', '')]\n",
      "[' ']\n",
      "[('ㅋ', 'ㅟ', 'ㄹ'), ('ㄱ', 'ㅛ', '')]\n",
      "['.', '.', '.']\n",
      "[' ']\n",
      "[('ㅇ', 'ㅑ', ''), ('ㅁ', 'ㅜ', 'ㅌ'), ('ㅌ', 'ㅜ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㄷ', 'ㅜ', 'ㅁ')]\n",
      "[' ']\n",
      "[('ㅂ', 'ㅕ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㄷ', 'ㅏ', 'ㅈ'), ('ㅆ', 'ㅣ', '')]\n",
      "[' ']\n",
      "[('ㄲ', 'ㅏ', 'ㄱ')]\n",
      "[('ㄲ', 'ㅣ', 'ㄹ')]\n",
      "[' ']\n",
      "[('ㅅ', 'ㅣ', 'ㅀ'), ('ㅎ', 'ㅜ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㄱ', 'ㅛ', 'ㅅ')]\n",
      "['.']\n",
      "[' ']\n",
      "[('ㄲ', 'ㅐ', 'ㅁ'), ('ㅃ', 'ㅣ', 'ㅇ'), ('ㅇ', 'ㅡ', 'ㄿ')]\n",
      "[' ']\n",
      "['2', '0']\n",
      "[('ㅇ', 'ㅕ', '')]\n",
      "[' ']\n",
      "[('ㄴ', 'ㅕ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㄷ', 'ㅑ', ''), ('ㄴ', 'ㅕ', 'ㄱ'), ('ㅂ', 'ㅛ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㄱ', 'ㅗ', 'ㄷ')]\n",
      "[' ']\n",
      "[('ㅈ', 'ㅜ', 'ㅇ')]\n",
      "[' ']\n",
      "[('ㅉ', 'ㅔ', ''), ('ㅇ', 'ㅟ', 'ㄹ')]\n",
      "[' ']\n",
      "[('ㄱ', 'ㅟ', 'ㅂ'), ('ㅍ', 'ㅜ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㄴ', 'ㅏ', 'ㄱ')]\n",
      "[('ㅍ', 'ㅏ', 'ㅆ')]\n",
      "[('ㄸ', 'ㅓ', 'ㄴ')]\n",
      "[' ']\n",
      "[('ㄱ', 'ㅗ', 'ㅈ')]\n",
      "['.']\n",
      "별 한 게도 앗갑담. 왜 사람듯릭 별 1개를 쥰눈징 걱걱본 사람믐롯석 맒록 섧멍핥쟈닐 댓긂룐눈 녀뮤 귈교... 야묻둔 둠 변 닺시 각길 싫훈 굣. 갬빙읊 20여 년 댜녁뵨 곧 중 제윌 귑분 낙밧던 곶.\n"
     ]
    }
   ],
   "source": [
    "import hgtk\n",
    "\n",
    "sentence = []\n",
    "for token in tokens:\n",
    "    chars = [hgtk.letter.decompose(c) if hgtk.checker.is_hangul(c) else c for c in token]\n",
    "    print(chars)\n",
    "    normalized_chars = []\n",
    "    for char in chars:       \n",
    "        if isinstance(char, tuple) and len(char) == 3:\n",
    "            cho, jung, jong = char\n",
    "\n",
    "            # 초성, 종성 변환\n",
    "            cho = to_plainWord(cho)\n",
    "            jong = to_plainWord(jong)\n",
    "            \n",
    "            normalized_char = hgtk.letter.compose(cho, jung, jong)\n",
    "            normalized_chars.append(normalized_char)\n",
    "        else:\n",
    "            # 한글이 아니면 그대로 추가\n",
    "            normalized_chars.append(char)\n",
    "\n",
    "    sentence.append(''.join(normalized_chars))\n",
    "\n",
    "print(''.join(sentence))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45016e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
